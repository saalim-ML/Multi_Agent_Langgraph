# -*- coding: utf-8 -*-
"""Multi-Agent-Langgraph.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TdEhwp21wmAFLWYa5-Bcgvg0lRX8olBL

**Multi Agent AI Using Langgraph**

-------------------------------------------------
*   Planner Node
*   Executer Node
"""

!pip install

!pip install -q langgraph

!pip install -q langchain-google-genai

from typing import List, Optional, TypedDict

from google.colab import userdata
gemini_api=userdata.get('GEMINI_API_KEY')

class AgentState(TypedDict,total=False):
  user_input: str
  task_list: List[str]
  final_output: Optional[str]

from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    api_key=gemini_api,
    model="gemini-2.5-flash",
    temperature=0.1
)

def planner_node(state: dict) -> dict:
    prompt = f"Break this task into 2-3 steps: {state['user_input']}"
    response  = llm.invoke(prompt)  # Assuming you have a function defined to call the LLM
    steps = response.content
    step_lines = [line.strip("- ").strip() for line in steps.split("\n") if line.strip()]
    print("ðŸ“Œ Planner Output:", step_lines)
    return {"task_list": step_lines}

def executor_node(state: dict) -> dict:
    steps = state.get("task_list", [])
    final_output = " -> ".join(steps) + " -> Done!"
    return {"final_output": final_output}

import langgraph.graph

from langgraph.graph import StateGraph

graph = StateGraph(state_schema=AgentState)

graph.add_node("planner", planner_node)
graph.add_node("executor", executor_node)

graph.set_entry_point("planner")
graph.add_edge("planner", "executor")
graph.set_finish_point("executor")

graph_compiled = graph.compile()

from IPython.display import Image, display
try:
    display(Image(graph_compiled.get_graph().draw_mermaid_png()))
except Exception:
    pass

state = {"user_input": "What is Multi Agent?"}
final_state = graph_compiled.invoke(state)

print(final_state["final_output"])